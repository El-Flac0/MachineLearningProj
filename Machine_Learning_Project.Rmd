---
title: "Dumb Bell Lifts - Machine Learning Project"
author: "Andrew Laws"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE}
library(caret)
library(ggplot2)
```

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, our goal was to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants to predict how well they performed the activity of lifting a barbell.

First, download the data from source, convert NA, Div/0!, and blanks to NA.

```{r, eval=TRUE}
bellTrain <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", na.strings=c("NA","#DIV/0!",""))
bellTest <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", na.strings=c("NA","#DIV/0!",""))
```

##Pre-processing
It is crucial to perform the same pre-processing on both the training and testing data sets. 

```{r, eval=TRUE}
#remove columns where 90% of values are 'NA'
bellTrainClean <- bellTrain[, -which(colMeans(is.na(bellTrain)) > 0.9)]
bellTestClean <- bellTest[, -which(colMeans(is.na(bellTest)) > 0.9)]

# Remove the 1st column, which appears to be an index number
bellTrain <- bellTrainClean[,-1]
bellTest <- bellTestClean[,-1]

# check the number of remaining NAs in the datasets
sum(is.na(bellTrain))
sum(is.na(bellTest))
```

There are no remaing NAs in the dataframe, so no further imputation using the caret package is necessary.

## Dataset Partition
The dataset must be partitioned for training and validation to compute the out-of-sample error, as the test set should only be used once, for a final test. I selected a 60/40 split between training data and validation data.

```{r, echo=TRUE, eval=TRUE}
set.seed(0666)
bellTrainSplit <- createDataPartition(bellTrain$classe, p=0.6, list=FALSE)
bellTrain <- bellTrain[bellTrainSplit,]
bellValid <- bellTrain[-bellTrainSplit,]
```

#Prediction Models

I used both the bootstrap aggregate classification tree method (treebag) within the caret package.

##K-fold cross validation

Cross-validation is a resampling procedure used to evaluate machine learning models on a limited data sample. The data is split into 'k' number of groups, and each group is treated as test data, while the remaining groups are treated like a training data set. For the purpose of this exercise k=10.

```{r, eval=TRUE}
kControl <- trainControl(method="cv", number=10)
```

## Classification Trees

Decision tree learning is a method commonly used in data mining and machine learning. The goal is to create a model that predicts the value of a target variable based on several input variables. I used the bootstrap aggregate decision tree method to produce a more accurate model.

```{r, eval=TRUE}
bellTrainTree <- train(classe ~ ., data=bellTrain, method="treebag", trControl=kControl)
print(bellTrainTree)
```

```{r, eval=TRUE}
predictBellTrain <- predict(bellTrainTree, bellValid)
bellTrainMatrix <- confusionMatrix(bellValid$classe, predictBellTrain)
print(bellTrainMatrix)
df <-data.frame(bellTrainMatrix$table)
ggplot(data =  df, mapping = aes(x = Reference, y = Prediction)) +
  geom_tile(aes(fill = Freq), colour = "white") +
  geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
  scale_fill_gradient(low = "blue", high = "red") +
  theme_bw() + theme(legend.position = "none")
```

As can be seen the accuracy of the model is 0.99, which means the out-of-sample error is 0.01. The bootstrapped aggregate classification tree model predicts the classe with total accuracy. 

### Predicting Test Data

At this point I was intending to predict using the random forest model, however the near-perfect accuracy of the treebag model makes that analysis redundant.

Instead I can now move to predicting the test data.

```{r, eval=TRUE}
predictTest <- predict(bellTrainTree, bellTest)
print(predictTest)
```